{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"InfraFlux","text":"<p>InfraFlux is an opinionated, push-button, multi-cloud Kubernetes platform inspired by ElfHosted and the Geek-Cookbook\u2019s \u201crecipe\u201d model.</p> <p>Core stack</p> <ul> <li>Cluster API (CAPI) for cluster lifecycle across AWS, Azure, GCP, and Proxmox.</li> <li>Talos Linux for immutable, API-driven node OS (no SSH, less drift).</li> <li>Cilium as CNI with kube-proxy replacement (eBPF) for a lean dataplane.</li> <li>FluxCD for GitOps delivery of curated app bundles (\u201crecipes\u201d).</li> <li>Crossplane (optional) to provision cloud resources via Kubernetes CRDs.</li> </ul> <p>Repo highlights</p> <ul> <li><code>/management</code> \u2013 management cluster bootstrap (clusterctl, Talos, Flux).</li> <li><code>/clusters</code> \u2013 provider-agnostic templates + per-provider overlays.</li> <li><code>/recipes</code> \u2013 Flux Kustomizations/HelmReleases for app bundles.</li> <li><code>/crossplane</code> \u2013 providers, compositions, and claims for cloud resources.</li> <li><code>/cli</code> \u2013 minimal Go CLI (<code>infraflux</code>) that renders plans/manifests.</li> </ul> <p>InfraFlux favors declarative config and GitOps. The CLI helps render/compose manifests; agents code, humans review, Git reconciles.</p>"},{"location":"architecture/","title":"Architecture","text":"<pre><code>+--------------------+        Git (this repo)        +--------------------+\n|  Developer/Agent   | ----------------------------&gt; |   Flux Controllers |\n+--------------------+   (mgmt cluster)               +--------------------+\n        |\n        | Kustomizations / HelmReleases\n        v\n+--------------------+\n|     Workloads      |\n|  (CAPI + Talos +   |\n|  Cilium + Apps)    |\n+--------------------+\n</code></pre>"},{"location":"architecture/#layers","title":"Layers","text":"<ul> <li>Management: Flux, Cluster API core + providers (CAPA/CAPZ/CAPG/CAPMOX), optional Crossplane.</li> <li>Workload: CAPI-created clusters; Talos nodes; Cilium networking; Flux delivers recipes.</li> </ul>"},{"location":"architecture/#why-this-design","title":"Why this design","text":"<ul> <li>Portability: CAPI abstracts provider details</li> <li>Determinism: Talos eliminates OS drift</li> <li>Simplicity: Cilium with kube-proxy replacement reduces moving parts</li> <li>GitOps: Flux reconciles application/infrastructure state from Git</li> </ul>"},{"location":"cli/","title":"CLI Reference (<code>infraflux</code>)","text":"<p>The CLI renders plans/manifests and orchestrates composition. It does not apply to live clusters.</p>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#infraflux-init","title":"<code>infraflux init</code>","text":"<p>Bootstrap artifacts for the management cluster:</p> <ul> <li>Renders/prints steps for <code>clusterctl init</code> with selected providers.</li> <li>Renders Flux bootstrap pointing to this repo.</li> </ul>"},{"location":"cli/#init-flags","title":"<code>init</code> Flags","text":"<ul> <li><code>--git-repo</code> (required): Git URL for Flux bootstrap.</li> <li><code>--providers</code>: comma-separated (default: aws,azure,gcp,proxmox).</li> <li><code>--namespace</code>: management namespace (default: <code>infraflux-system</code>).</li> </ul>"},{"location":"cli/#infraflux-up","title":"<code>infraflux up</code>","text":"<p>Render a workload cluster plan (CAPI + Talos) and the post-creation app setup.</p>"},{"location":"cli/#up-flags","title":"<code>up</code> Flags","text":"<ul> <li><code>--provider</code>: <code>aws|azure|gcp|proxmox</code></li> <li><code>--name</code>: cluster name</li> <li><code>--region</code>: cloud region (if applicable)</li> <li><code>--workers</code>, <code>--cpu</code>, <code>--memory</code>, <code>--k8s</code></li> </ul>"},{"location":"cli/#infraflux-destroy","title":"<code>infraflux destroy</code>","text":"<p>Render a deletion plan for a named cluster.</p>"},{"location":"cli/#common-flags","title":"Common flags","text":"<ul> <li><code>--dry-run</code>: render only, no side effects</li> <li><code>-c, --config</code>: optional config file for defaults</li> </ul> <p>The agent will implement file outputs to <code>./out/&lt;cluster&gt;/</code> so CI can apply plans safely.</p>"},{"location":"crossplane/","title":"Crossplane","text":"<p>InfraFlux ships a minimal Crossplane skeleton you can opt into.</p>"},{"location":"crossplane/#providers","title":"Providers","text":"<p>Pinned provider packages live in <code>crossplane/base/</code>:</p> <ul> <li>AWS: <code>provider-aws.yaml</code></li> <li>Azure: <code>provider-azure.yaml</code></li> <li>GCP: <code>provider-gcp.yaml</code></li> </ul>"},{"location":"crossplane/#providerconfig-and-secrets","title":"ProviderConfig and Secrets","text":"<p><code>crossplane/base/providerconfigs.yaml</code> defines <code>ProviderConfig</code> objects referencing Secrets. Store credentials as SOPS-encrypted Secrets under <code>sops/</code>.</p>"},{"location":"crossplane/#compositions-and-claims","title":"Compositions and Claims","text":"<ul> <li>Compositions live in <code>crossplane/compositions/</code></li> <li>Example XR/XRD for Postgres are provided (AWS sample)</li> <li>A claim (e.g., <code>CompositePostgresInstance</code>) can be created in-cluster by apps</li> </ul>"},{"location":"crossplane/#recipes-integration","title":"Recipes integration","text":"<p>Recipes can depend on Crossplane-managed resources by waiting on secrets/config to appear. Keep sensitive values in SOPS-encrypted Secrets and mount them at runtime.</p>"},{"location":"faq/","title":"FAQ","text":"<p>Q: Why Talos instead of Ubuntu + Ansible? A: Immutable API-driven nodes avoid drift and reduce bootstrap flakiness, enabling truly \u201cpush-button\u201d flows.</p> <p>Q: Can I use Argo CD instead of Flux? A: Yes\u2014InfraFlux ships Flux by default. You can add Argo as a recipe or swap if your org standardizes on Argo.</p> <p>Q: Do I need Crossplane? A: No. It\u2019s optional, but ideal if you want cloud resources (DBs, buckets, DNS) to be managed in the same GitOps loop.</p> <p>Q: How do I change storage from Longhorn to a cloud CSI? A: Replace <code>recipes/base/storage-longhorn-helmrelease.yaml</code> with your provider CSI and update the Kustomization.</p>"},{"location":"gitops/","title":"GitOps &amp; Repositories","text":"<p>InfraFlux uses Flux as the GitOps engine.</p>"},{"location":"gitops/#flux-bootstrap-layout","title":"Flux bootstrap layout","text":"<p>management/flux/ namespace.yaml kustomization.yaml gotk-components.yaml # generated by flux install --export gotk-sync.yaml # recipes/base gotk-sync-observability.yaml gotk-sync-devtools.yaml sources/ git/infraflux.yaml helm/*.yaml # catalogs (cilium, jetstack, bitnami, etc.)</p>"},{"location":"gitops/#adding-a-new-git-source","title":"Adding a new Git source","text":"<p>Add another <code>GitRepository</code> and a <code>Kustomization</code> referencing it; Flux will pull and apply it just like the main repo.</p>"},{"location":"gitops/#helm-catalogs","title":"Helm catalogs","text":"<p>HelmRepository objects are declared under <code>management/flux/sources/helm</code>. Do not mix catalog definitions into recipe folders.</p>"},{"location":"installation/","title":"Installation","text":"<p>This guide walks you from a blank machine to a management cluster syncing InfraFlux, and rendering a workload cluster plan with curated recipes.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Install locally (or in CI):</p> <ul> <li>go &gt;= 1.22</li> <li>kubectl &gt;= 1.28</li> <li>clusterctl &gt;= 1.6</li> <li>talosctl &gt;= 1.7</li> <li>flux &gt;= 2.2</li> <li>sops + age</li> <li>yq (optional; enables YAML verify in hooks)</li> </ul> <p>Optionally enable repo git hooks:</p> <pre><code>git config core.hooksPath githooks\n</code></pre>"},{"location":"installation/#get-the-sources-and-build-the-cli-render-only","title":"Get the sources and build the CLI (render-only)","text":"<pre><code>git clone https://github.com/binghzal/infraflux\ncd infraflux\nmake build-cli\n./bin/infraflux --help\n</code></pre>"},{"location":"installation/#provision-a-management-cluster","title":"Provision a management cluster","text":"<p>Use your preferred method to create a small management cluster (Talos recommended). Once KUBECONFIG is set, bootstrap Flux and point it at this repo.</p> <pre><code># Install Flux controllers into the management cluster\nflux install --export &gt; management/flux/gotk-components.yaml\nkubectl apply -k management/flux\n</code></pre> <p>The management manifests will:</p> <ul> <li>Create HelmRepository sources   (cilium, jetstack, bitnami, prometheus-community, argo, longhorn,   envoy-gateway, grafana, ingress-nginx, hashicorp)</li> <li>Configure Git sync to this repository</li> <li>Sync default bundles: recipes/base, recipes/observability, recipes/devtools</li> </ul>"},{"location":"installation/#sops-secrets-setup","title":"SOPS secrets setup","text":"<p>Generate an age key and configure SOPS policy. Store provider credentials as encrypted Secrets.</p> <pre><code># generate an age keypair\nage-keygen -o ~/.config/sops/age/keys.txt\n\n# edit sops/.sops.yaml to include your recipient public key\n# then create secrets (examples live in sops/)\n</code></pre> <p>Never commit plaintext secrets. Use the examples in <code>sops/</code> as a reference.</p>"},{"location":"installation/#render-a-workload-cluster-plan","title":"Render a workload cluster plan","text":"<p>Render manifests for your target provider; output goes to <code>out/&lt;cluster&gt;/</code>.</p> <pre><code>./bin/infraflux up \\\n  --provider proxmox \\\n  --name lab \\\n  --workers 2 --cpu 4 --memory 8 \\\n  --k8s 1.30 \\\n  --recipes base,observability,devtools,media\n</code></pre> <p>This produces:</p> <ul> <li>out/lab/cluster/ \u2014 CAPI + Talos manifests</li> <li>out/lab/addons/cilium/ \u2014 Cilium HelmRelease</li> <li>out/lab/addons/gateway/ \u2014 Envoy Gateway HelmRelease</li> <li>out/lab/recipes/ \u2014 per-cluster Kustomizations pointing to recipe bundles</li> </ul>"},{"location":"installation/#apply-outside-the-scope-of-infraflux-agent","title":"Apply (outside the scope of InfraFlux agent)","text":"<p>InfraFlux is render-only. To proceed, a human/CI can apply the plan to the management cluster:</p> <pre><code># example only \u2014 adjust namespaces and paths as needed\nkubectl apply -f out/lab/cluster/\nkubectl apply -f out/lab/addons/\nkubectl apply -f out/lab/recipes/\n</code></pre> <p>Flux will take over reconciliation once the manifests are applied.</p>"},{"location":"installation/#recipes-and-catalogs","title":"Recipes and catalogs","text":"<ul> <li>Bundles live under <code>recipes/</code> (base, observability, devtools, media)</li> <li>Per-cluster Kustomizations are generated in <code>out/&lt;cluster&gt;/recipes/*.yaml</code></li> <li>Helm catalogs are defined in <code>management/flux/sources/helm/</code></li> </ul> <p>To add apps, commit new HelmReleases under a bundle and include that bundle via <code>--recipes</code>.</p>"},{"location":"installation/#crossplane-optional","title":"Crossplane (optional)","text":"<ul> <li>Providers are pinned in <code>crossplane/base/</code></li> <li>ProviderConfigs reference SOPS-encrypted Secrets</li> <li>Compositions live in <code>crossplane/compositions/</code></li> </ul> <p>You can define claims (e.g., Postgres) and wire recipes to depend on them.</p>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Verify YAML: install <code>yq</code> and run <code>make verify-yaml</code></li> <li>Run tests: <code>make test</code></li> <li>Render sample: <code>make render-sample</code></li> </ul> <p>See also: Troubleshooting and FAQ docs.</p>"},{"location":"networking/","title":"Networking (Cilium &amp; Gateway)","text":""},{"location":"networking/#cilium","title":"Cilium","text":"<p>InfraFlux installs Cilium via Helm (Flux <code>HelmRelease</code>) with kube-proxy replacement enabled:</p> <ul> <li>Lower latency/CPU vs iptables-based kube-proxy.</li> <li>eBPF-powered services, network policies, and Hubble observability (optional).</li> </ul> <p>Edit/overlay values in <code>clusters/cilium/helmrelease.yaml</code> as needed:</p> <ul> <li><code>k8sServiceHost</code> / <code>k8sServicePort</code> for API server (optional, Talos often sets these).</li> <li>Enable Hubble UI by adding values and a HelmRelease for it.</li> </ul>"},{"location":"networking/#gateway-api-envoy-gateway","title":"Gateway API + Envoy Gateway","text":"<p>We ship a <code>HelmRelease</code> for Envoy Gateway under <code>clusters/gateway/</code>. Use HTTPRoute/TLSRoute/GRPCRoute for modern, portable L7 ingress.</p> <p>If you need NGINX, add a <code>HelmRelease</code> using the <code>ingress-nginx</code> catalog instead.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>Goal: get a management cluster syncing this repo, then render a workload cluster and auto-install recipes.</p> <p>For complete steps, see the Installation guide.</p>"},{"location":"quickstart/#1-prerequisites","title":"1) Prerequisites","text":"<p>Install locally (or in CI): go, kubectl, clusterctl, talosctl, flux, sops + age, yq.</p>"},{"location":"quickstart/#2-build-the-cli-render-only","title":"2) Build the CLI (render-only)","text":"<pre><code>git clone https://github.com/binghzal/infraflux\ncd infraflux\n\n# share the versioned git hooks\ngit config core.hooksPath githooks\nchmod +x githooks/*    # enable hooks locally\n# (uses Git\u2019s supported hooksPath mechanism)  # :contentReference[oaicite:5]{index=5}\n\n# build the CLI\nmake build-cli\n./bin/infraflux --help\n</code></pre>"},{"location":"quickstart/#3-bootstrap-flux-in-your-management-cluster","title":"3) Bootstrap Flux in your management cluster","text":"<pre><code>flux install --export &gt; management/flux/gotk-components.yaml\nkubectl apply -k management/flux\n</code></pre>"},{"location":"quickstart/#4-configure-secrets-sops","title":"4) Configure secrets (SOPS)","text":"<ul> <li>Generate an age key; update <code>sops/.sops.yaml</code> recipients</li> <li>Create provider credential Secrets as SOPS-encrypted files</li> </ul>"},{"location":"quickstart/#5-render-a-workload-cluster-plan-proxmox-example","title":"5) Render a workload cluster plan (Proxmox example)","text":"<pre><code>./bin/infraflux up \\\n  --provider proxmox \\\n  --name lab \\\n  --workers 2 --cpu 4 --memory 8 \\\n  --k8s 1.30 \\\n  --recipes base,observability,devtools,media\n</code></pre> <p>Outputs are written to <code>out/&lt;cluster&gt;/</code>.</p>"},{"location":"quickstart/#6-next-steps","title":"6) Next steps","text":"<p>Apply manifests with kubectl (human/CI), then Flux reconciles state.</p> <p>See also: Installation, Recipes, Troubleshooting.</p>"},{"location":"recipes/","title":"Recipes","text":"<p>Recipes are composable app bundles delivered through Flux. Each bundle is a directory with:</p> <ul> <li><code>kustomization.yaml</code></li> <li>One or more <code>HelmRelease</code> manifests</li> <li>Optional <code>ConfigMap</code>/<code>Secret</code> overlays (SOPS encrypted if needed)</li> </ul>"},{"location":"recipes/#included-bundles","title":"Included bundles","text":"<ul> <li><code>recipes/base</code>: cert-manager, ExternalDNS, storage (Longhorn by default)</li> <li><code>recipes/observability</code>: kube-prometheus-stack (Prometheus, Alertmanager, Grafana)</li> <li><code>recipes/devtools</code>: Argo CD (optional, primarily as an example)</li> <li><code>recipes/media</code>: placeholder bundle and namespace; add the media apps you want.</li> </ul>"},{"location":"recipes/#creating-a-new-bundle","title":"Creating a new bundle","text":"<ol> <li>Create <code>recipes/&lt;bundle&gt;/kustomization.yaml</code>.</li> <li>Add <code>HelmRelease</code> objects that reference catalogs from <code>management/flux/sources/helm</code>.</li> <li>If secrets are needed, commit SOPS-encrypted resources to <code>sops/</code>.</li> </ol>"},{"location":"recipes/#enabling-bundles","title":"Enabling bundles","text":"<ul> <li>Wire a <code>Kustomization</code> in <code>management/flux/gotk-sync-&lt;bundle&gt;.yaml</code> pointing to <code>./recipes/&lt;bundle&gt;</code>.</li> <li>Or when rendering with the CLI, include it via <code>--recipes base,observability,devtools,media</code> to generate per-cluster Kustomizations.</li> <li>Commit and let Flux reconcile.</li> </ul>"},{"location":"secrets/","title":"Secrets (SOPS &amp; age)","text":"<p>InfraFlux uses SOPS with age recipients for secret encryption in Git.</p>"},{"location":"secrets/#setup","title":"Setup","text":"<ol> <li>Generate a key:    <pre><code>age-keygen -o sops/keys/agekey.txt\nAdd the public key to sops/.sops.yaml under creation_rules.age.\nUsage\nCreate a Kubernetes Secret manifest (do not commit plaintext).\nRun sops --encrypt --in-place my-secret.enc.yaml.\nKeep the *.enc.yaml file; the CI/runner or operator decrypts at apply time.\nConventions\nEncrypted files must match sops/.sops.yaml rules.\nStore cloud provider creds here, never in plain YAML.\n</code></pre></li> </ol>"},{"location":"secrets/#docscrossplanemd","title":"<code>docs/crossplane.md</code>","text":"<pre><code># Crossplane (optional)\n\nUse Crossplane to model cloud resources (RDS, S3, Cloud DNS, etc.) as Kubernetes CRDs and reconcile them via GitOps.\n\n## Base installation\n\n`crossplane/base/` declares provider packages:\n\n- `provider-aws`, `provider-azure`, `provider-gcp`\n\n&gt; The coding agent should pin tested versions and add `ProviderConfig` &amp; creds (SOPS).\n\n## Compositions\n\n- `crossplane/compositions/` holds XRDs and provider-specific Compositions.\n- Example: `XPostgresDatabase` + `Composition` for AWS RDS.\n\n## Flow\n\n1. Install provider(s) and set `ProviderConfig`.\n2. Apply XRD + Composition(s).\n3. Create Claim (e.g., `PostgresDatabase`) in the app namespace; Crossplane provisions per composition.\n</code></pre>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#flux-not-reconciling","title":"Flux not reconciling","text":"<ul> <li>Check <code>kubectl -n flux-system get kustomizations,helmreleases,gitrepositories,helmrepositories</code>.</li> <li>Describe failing resources (<code>kubectl describe ...</code>) to see fetch/apply errors.</li> </ul>"},{"location":"troubleshooting/#recipes-fail-due-to-missing-catalogs","title":"Recipes fail due to missing catalogs","text":"<ul> <li>Ensure <code>management/flux/kustomization.yaml</code> includes all HelmRepository sources you need.</li> </ul>"},{"location":"troubleshooting/#secrets-missing","title":"Secrets missing","text":"<ul> <li>Validate SOPS decryption in your apply context.</li> <li>Confirm <code>.sops.yaml</code> matches your encrypted filenames/paths.</li> </ul>"},{"location":"troubleshooting/#cluster-api-components-not-installed","title":"Cluster API components not installed","text":"<ul> <li>Re-export <code>gotk-components.yaml</code> after <code>flux install</code> and commit.</li> <li>Confirm <code>clusterctl init</code> providers match your intended targets.</li> </ul>"},{"location":"providers/aws/","title":"AWS (CAPA)","text":""},{"location":"providers/aws/#credentials","title":"Credentials","text":"<ul> <li>Create an IAM user or role with permissions for EC2, VPC, ELB/NLB, IAM (limited), Route53 (if using ExternalDNS).</li> <li>Store keys as a SOPS-encrypted Secret.</li> </ul>"},{"location":"providers/aws/#networking","title":"Networking","text":"<ul> <li>Recommended: dedicated VPC with public/private subnets and NAT if needed.</li> <li>Specify subnets, security groups, and load balancer type via the provider overlay.</li> </ul>"},{"location":"providers/aws/#overlays","title":"Overlays","text":"<ul> <li>Edit <code>clusters/aws/values.example.yaml</code> and/or Kustomize literals in <code>clusters/aws/kustomization.yaml</code>:</li> <li>instance types (<code>t3.medium</code>, <code>t3.large</code>, etc.)</li> <li>region (<code>us-east-1</code>)</li> <li>control plane/worker replicas</li> <li>Kubernetes minor and Talos versions</li> </ul>"},{"location":"providers/aws/#notes","title":"Notes","text":"<ul> <li>Use EBS CSI if you want dynamic volumes; Longhorn is default and cloud-agnostic, but you may prefer managed CSI on AWS.</li> </ul>"},{"location":"providers/azure/","title":"Azure (CAPZ)","text":""},{"location":"providers/azure/#credentials","title":"Credentials","text":"<ul> <li>Service Principal with least-privilege for VMSS, VNets, Load Balancers, Managed Disks, and optionally DNS Zones.</li> <li>Store as SOPS Secret; reference in CAPZ ProviderConfig.</li> </ul>"},{"location":"providers/azure/#networking","title":"Networking","text":"<ul> <li>Prepare a VNet with subnets and NSGs or let CAPZ create defaults per overlay config.</li> </ul>"},{"location":"providers/azure/#overlays","title":"Overlays","text":"<ul> <li>Mirror the AWS layout under <code>clusters/azure/</code>, setting:</li> <li>location (e.g., <code>westeurope</code>)</li> <li>VM sizes (e.g., <code>Standard_D2s_v5</code>)</li> <li>replicas and versions.</li> </ul>"},{"location":"providers/azure/#notes","title":"Notes","text":"<ul> <li>Consider Azure Disk/Files CSI if you prefer managed storage over Longhorn.</li> </ul>"},{"location":"providers/common-prereqs/","title":"Providers \u2013 Common Prerequisites","text":"<p>All providers share a few concepts:</p> <ul> <li>Credentials: store them as SOPS-encrypted Secrets; reference them from provider configs or kube-controllers that need them.</li> <li>Networks: either provision via Crossplane/OpenTofu/Pulumi or use existing; CAPI will need subnet/SG info depending on provider.</li> <li>Images: for Talos nodes, use official cloud images or build/import images appropriate to each provider (Proxmox needs a VM template).</li> </ul> <p>The management cluster itself can be anywhere (cloud or Proxmox). It hosts Flux and CAPI providers to create workload clusters elsewhere.</p>"},{"location":"providers/gcp/","title":"GCP (CAPG)","text":""},{"location":"providers/gcp/#credentials","title":"Credentials","text":"<ul> <li>A service account JSON key with roles for Compute, Networking, and optionally Cloud DNS.</li> <li>Encrypt with SOPS; mount or reference in CAPG controller.</li> </ul>"},{"location":"providers/gcp/#networking","title":"Networking","text":"<ul> <li>Use a custom VPC with subnets and firewall rules or rely on defaults with tight security overlays.</li> </ul>"},{"location":"providers/gcp/#overlays","title":"Overlays","text":"<ul> <li><code>clusters/gcp/</code> mirrors others:</li> <li>region/zone (e.g., <code>europe-west1-b</code>)</li> <li>machine type (<code>e2-standard-2</code>, etc.)</li> <li>replicas and versions</li> </ul>"},{"location":"providers/gcp/#notes","title":"Notes","text":"<ul> <li>For managed storage, use GCE PD CSI; otherwise Longhorn is cloud-agnostic.</li> </ul>"},{"location":"providers/proxmox/","title":"Proxmox (CAPMOX)","text":""},{"location":"providers/proxmox/#credentials","title":"Credentials","text":"<ul> <li>Proxmox API token (realm, user, token name, secret).</li> <li>Encrypt with SOPS; the CAPMOX controller references it.</li> </ul>"},{"location":"providers/proxmox/#templates","title":"Templates","text":"<ul> <li>Prepare a Talos VM template in Proxmox (cloud-init capable or via documented CAPMOX method).</li> <li>Ensure storage pool and network bridge are configured.</li> </ul>"},{"location":"providers/proxmox/#overlays","title":"Overlays","text":"<ul> <li><code>clusters/proxmox/</code> should define:</li> <li><code>node</code> (PVE host)</li> <li><code>storage</code> (e.g., <code>local-lvm</code>)</li> <li><code>network</code> bridge (e.g., <code>vmbr0</code>)</li> <li>CPU, memory, disk sizes</li> <li>replicas and versions</li> </ul>"},{"location":"providers/proxmox/#notes","title":"Notes","text":"<ul> <li>For LoadBalancing, use Kube-VIP or MetalLB (ship as optional recipe).</li> </ul>"}]}